# ğŸ›¡ï¸ Resilience Patterns - Implementation Guide

## âœ… Patrones Aplicados

Los siguientes patrones de resilience se aplicaron siguiendo las mejores prÃ¡cticas de la industria:

---

## 1ï¸âƒ£ LLM Service (`app/services/llm_service.py`)

### `generate_answer()` - Respuestas principales

```python
@with_timeout(30)
@with_retry(max_attempts=3, min_wait=1, max_wait=5)
@with_circuit_breaker(ollama_breaker)
async def generate_answer(question, context):
    ...
```

**Stack de protecciÃ³n:**
1. **Circuit Breaker**: Si Ollama falla 5 veces consecutivas â†’ fail-fast por 60s
2. **Retry**: Hasta 3 intentos con backoff exponencial (1s, 2s, 4s)
3. **Timeout**: Cancela si excede 30 segundos

**Beneficio**: 
- Evita esperar 30s por cada falla cuando Ollama estÃ¡ caÃ­do
- RecuperaciÃ³n automÃ¡tica de errores transitorios
- ProtecciÃ³n contra requests que se cuelgan

---

### `generate_greeting_response()` - Saludos

```python
@with_timeout(15)
@with_retry(max_attempts=2, min_wait=1, max_wait=3)
@with_circuit_breaker(ollama_breaker)
async def generate_greeting_response(greeting_text):
    ...
```

**Diferencias con generate_answer:**
- Timeout mÃ¡s corto (15s vs 30s) - los saludos deben ser rÃ¡pidos
- Menos reintentos (2 vs 3) - menos crÃ­tico que respuestas
- **Comparte circuit breaker** con `generate_answer` (importante!)

---

## 2ï¸âƒ£ Web Search Service (`app/services/web_search_service.py`)

### `search()` - BÃºsqueda en Wikipedia

```python
@with_timeout(20)
@with_retry(max_attempts=2, min_wait=1, max_wait=3, exceptions=(Exception,))
def search(query, max_results=3):
    ...
```

**ProtecciÃ³n:**
- Timeout: 20s mÃ¡ximo (Wikipedia debe responder rÃ¡pido)
- Retry: 2 intentos para errores de red

**Por quÃ© Exception genÃ©rico:**
- Wikipedia API puede lanzar mÃºltiples tipos de errores
- Mejor capturar todo y reintentar

---

### `search_and_summarize()` - BÃºsqueda + LLM

```python
@with_timeout(60)
async def search_and_summarize(question, max_results=2):
    ...
```

**Solo timeout:**
- 60s total (20s Wikipedia + 30s LLM + buffer)
- No retry porque ya tiene fallback interno (raw snippets)

---

## 3ï¸âƒ£ Database (`app/database/database.py`)

### `init_database()` - InicializaciÃ³n

```python
@with_retry(
    max_attempts=3,
    min_wait=2,
    max_wait=10,
    exceptions=(OperationalError, DBAPIError)
)
async def init_database():
    ...
```

**Por quÃ©:**
- MySQL puede no estar listo al inicio (Docker startup)
- Retry con backoff largo (2s, 4s, 8s) da tiempo a MySQL
- Solo reintenta errores de conexiÃ³n, no errores de schema

---

### `check_database_health()` - Health check

```python
@with_retry(
    max_attempts=2,
    min_wait=1,
    max_wait=3,
    exceptions=(OperationalError,)
)
async def check_database_health():
    ...
```

**Menos agresivo:**
- Solo 2 intentos (es un health check, no crÃ­tico)
- Backoff mÃ¡s corto (1s, 2s)

---

## ğŸ“Š ConfiguraciÃ³n por Servicio

| Servicio | Timeout | Retry Attempts | Backoff | Circuit Breaker |
|----------|---------|----------------|---------|-----------------|
| **LLM Answer** | 30s | 3 | 1sâ†’2sâ†’4s | âœ… (5 fails, 60s) |
| **LLM Greeting** | 15s | 2 | 1sâ†’2s | âœ… (shared) |
| **Wikipedia Search** | 20s | 2 | 1sâ†’2s | âŒ |
| **Wikipedia Summary** | 60s | âŒ | - | âŒ |
| **DB Init** | âˆ | 3 | 2sâ†’4sâ†’8s | âŒ |
| **DB Health** | âˆ | 2 | 1sâ†’2s | âŒ |

---

## ğŸ¯ Flujo de Ejemplo: Query con Ollama caÃ­do

### Sin resilience:
```
Request 1 â†’ Ollama timeout (30s) â†’ Error 500
Request 2 â†’ Ollama timeout (30s) â†’ Error 500
Request 3 â†’ Ollama timeout (30s) â†’ Error 500
...
Total time wasted: 90s+
```

### Con resilience:
```
Request 1 â†’ Ollama FAIL â†’ retry (wait 1s) â†’ FAIL â†’ retry (wait 2s) â†’ FAIL
           Total: 33s, fail_count=1

Request 2 â†’ Ollama FAIL â†’ retry â†’ FAIL â†’ retry â†’ FAIL
           Total: 33s, fail_count=2

...

Request 5 â†’ Ollama FAIL â†’ retry â†’ FAIL â†’ retry â†’ FAIL
           Total: 33s, fail_count=5

ğŸ”´ Circuit Breaker OPENS

Request 6 â†’ Circuit breaker OPEN â†’ Error 503 (0s) âš¡
Request 7 â†’ Circuit breaker OPEN â†’ Error 503 (0s) âš¡
...

After 60s â†’ Circuit breaker HALF_OPEN
Request N â†’ Tries again...
  Success? â†’ Circuit CLOSED âœ…
  Fail?    â†’ Circuit OPEN again âŒ
```

**Tiempo ahorrado**: Requests 6+ son instantÃ¡neos en lugar de 30s cada uno

---

## ğŸ” Monitoreo

### Ver estado de Circuit Breakers

**Endpoint**: `GET /health`

```json
{
  "services": {
    "ollama": {
      "available": true,
      "circuit_breaker": "closed"  // closed, open, half_open
    }
  }
}
```

**En cÃ³digo**:
```python
from app.utils.resilience import get_circuit_breaker_status

status = get_circuit_breaker_status()
# {
#   "ollama": {
#     "state": "closed",
#     "fail_counter": 0,
#     "opened_at": None
#   }
# }
```

---

## ğŸ§ª Testear Resilience

### 1. Apagar Ollama

```bash
# Detener Ollama
docker stop ollama  # o ctrl+c si corre local

# Hacer query
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "test"}'

# Primera vez: 3 retries (33s total)
# Quinta vez: Circuit breaker abre â†’ instant error âš¡
```

### 2. Latencia alta

```bash
# Simular latencia de red (Linux/Mac)
sudo tc qdisc add dev eth0 root netem delay 5000ms

# Request deberÃ­a cancelarse por timeout
```

### 3. MySQL caÃ­do

```bash
# Detener MySQL
docker-compose stop mysql

# Health check
curl http://localhost:8000/health
# "mysql": {"available": false}  â† despuÃ©s de 2 retries

# Levantar MySQL
docker-compose start mysql

# Health check auto-recupera
```

---

## ğŸ›ï¸ ConfiguraciÃ³n en `.env`

```bash
# Circuit Breaker
CIRCUIT_BREAKER_THRESHOLD=5      # Abre despuÃ©s de N fallas
CIRCUIT_BREAKER_TIMEOUT=60       # Reintenta despuÃ©s de N segundos

# Timeouts
OLLAMA_TIMEOUT=30                # LLM timeout (segundos)

# Retries
OLLAMA_RETRY_ATTEMPTS=3          # NÃºmero de reintentos
```

---

## âš ï¸ Importante: Orden de Decorators

**SIEMPRE este orden**:
```python
@with_timeout(30)      # 1. Outer: Timeout general
@with_retry(...)       # 2. Middle: Retry logic
@with_circuit_breaker  # 3. Inner: Fail-fast check
async def function():
    ...
```

**Â¿Por quÃ©?**
1. Timeout envuelve todo (incluye retries)
2. Retry envuelve la funciÃ³n real
3. Circuit breaker checks ANTES de ejecutar

**Orden incorrecto** âŒ:
```python
@with_circuit_breaker  # Si estÃ¡ afuera, timeout no aplica
@with_timeout(30)      
@with_retry(...)       
async def function():
    ...
```

---

## ğŸ“š Referencias

- [Circuit Breaker Pattern](https://martinfowler.com/bliki/CircuitBreaker.html) - Martin Fowler
- [Exponential Backoff](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/) - AWS
- [Resilience4j](https://resilience4j.readme.io/) - Java library (inspiraciÃ³n)
- [Polly](https://github.com/App-vNext/Polly) - .NET library (inspiraciÃ³n)

---

## âœ… Resumen

**Antes**: Servicios externos fallen â†’ App crashea o cuelga  
**Ahora**: Servicios externos fallan â†’ App se degrada gracefully

**Beneficios**:
- âš¡ Fail-fast cuando servicios estÃ¡n caÃ­dos (circuit breaker)
- ğŸ”„ Auto-recuperaciÃ³n de errores transitorios (retry)
- â±ï¸ ProtecciÃ³n contra requests colgados (timeout)
- ğŸ“Š Monitoreo del estado de servicios externos
